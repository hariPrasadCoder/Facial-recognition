{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "model = load_model('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forming rectangle aroung face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web cam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 1.5984377e-26 2.1082458e-17 8.1333174e-10]]\n",
      "[[1.0000000e+00 1.2796025e-34 0.0000000e+00 1.1280821e-09]]\n",
      "[[6.6865522e-07 2.5169634e-11 7.5129174e-11 9.9999928e-01]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1700795e-27]]\n",
      "[[1.0000000e+00 2.0824014e-35 1.4425968e-20 1.3621392e-13]]\n",
      "[[1.0000000e+00 1.6090446e-35 4.5775302e-31 1.4642168e-16]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 6.7461837e-31]]\n",
      "[[1.000000e+00 0.000000e+00 0.000000e+00 3.585501e-36]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7172749e-31]]\n",
      "[[1.000000e+00 0.000000e+00 0.000000e+00 4.683709e-30]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 4.9640563e-21]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3017543e-30]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5511662e-29]]\n",
      "[[1.000000e+00 0.000000e+00 0.000000e+00 3.086764e-33]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6580313e-29]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3586495e-25]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0399894e-24]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4073004e-18]]\n",
      "[[1.000000e+00 0.000000e+00 0.000000e+00 7.560859e-20]]\n",
      "[[8.8664514e-01 1.9410550e-31 2.2040622e-14 1.1335492e-01]]\n",
      "[[9.51925814e-01 8.46826590e-35 1.09732996e-13 4.80742380e-02]]\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3179148e-22]]\n",
      "[[9.9996853e-01 3.5567335e-32 4.8737176e-31 3.1488096e-05]]\n",
      "[[1.000000e+00 0.000000e+00 0.000000e+00 7.742721e-37]]\n",
      "[[9.9999988e-01 2.0044427e-37 1.9186636e-14 8.0695379e-08]]\n",
      "[[8.2373893e-01 6.7178401e-09 3.6261830e-04 1.7589837e-01]]\n",
      "[[9.0079264e-14 9.9998808e-01 1.1957547e-05 1.1732977e-11]]\n",
      "[[9.9999821e-01 3.7377734e-17 4.8633400e-09 1.7606151e-06]]\n",
      "[[1.0000000e+00 0.0000000e+00 1.1987849e-38 1.1926418e-14]]\n",
      "[[4.2213621e-17 1.0000000e+00 1.6418112e-15 4.4459257e-17]]\n",
      "[[1.0599626e-18 1.0000000e+00 4.5817860e-19 1.1046485e-19]]\n",
      "[[1.5205244e-05 0.0000000e+00 0.0000000e+00 9.9998474e-01]]\n",
      "[[1.3903867e-08 0.0000000e+00 2.0318717e-38 1.0000000e+00]]\n",
      "[[3.0099445e-14 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[1.40397555e-11 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "[[3.757894e-18 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[4.198492e-10 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[1.31215325e-11 0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "[[4.7514232e-24 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[6.4851454e-23 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[1.233595e-33 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[1.3890264e-20 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[3.023213e-36 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[1.4001275e-37 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[1.7779058e-29 0.0000000e+00 3.2495032e-28 1.0000000e+00]]\n",
      "[[4.1301695e-25 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[3.695822e-27 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[1.8468202e-28 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[4.4089586e-38 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[6.079919e-25 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[8.359513e-33 0.000000e+00 0.000000e+00 1.000000e+00]]\n",
      "[[1.4787971e-35 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n",
      "[[1.000000e+00 2.629571e-28 0.000000e+00 5.241193e-12]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    #canvas = detect(gray, frame)\n",
    "    #image, face =face_detector(frame)\n",
    "    \n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        im = Image.fromarray(face, 'RGB')\n",
    "           #Resizing into 128x128 because we trained the model with this image size.\n",
    "        img_array = np.array(im)\n",
    "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "                     \n",
    "        name=\"None matching\"\n",
    "        \n",
    "        if(pred[0][0]>0.5):\n",
    "            name='Hari'\n",
    "        elif(pred[0][1]>0.5):\n",
    "            name='Renga'\n",
    "        elif(pred[0][2]>0.5):\n",
    "            name='Uma'\n",
    "        elif(pred[0][3]>0.5):\n",
    "            name='Viji'\n",
    "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
